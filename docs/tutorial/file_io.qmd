---
title: Working with Files
execute:
  warning: false
---

The following highlights some DASCore features for working with IO.


## Reading from Remote Sources

DASCore can read files directly from remote sources using [UPath](https://github.com/fsspec/universal_pathlib), which provides unified access to various storage backends:

```python
import dascore as dc
from upath import UPath

# Read from GitHub
github_path = UPath("github://username:repo@/path/to/file.h5")
spool = dc.spool(github_path)

# Read from HTTP/HTTPS
http_path = UPath("https://example.com/data/file.h5")
spool = dc.spool(http_path)

# Read from S3
s3_path = UPath("s3://bucket-name/path/to/file.h5")
spool = dc.spool(s3_path)
```

For authentication with private repositories or cloud storage, you can pass credentials directly to UPath or use environment variables. See the [remote file access recipe](../recipes/remote_file_access.qmd) for detailed examples.


## Writing Patches to Disk

Patches can be written to disk using the `io` namespace. The following shows how to write a Patch to disk in the [DASDAE format](`dascore.io.dasdae`)

```{python}
from pathlib import Path
import dascore as dc

write_path = Path("output_file.h5")
patch = dc.get_example_patch()

patch.io.write(write_path, "dasdae")
```

```{python}
#| echo: false
if write_path.exists():
    write_path.unlink()
```

## DirectorySpool

The [DirectorySpool](`dascore.clients.dirspool.DirectorySpool`) is used to retrieve data from a directory of dascore-readable files. It has the same interface as other spools and is created with the [`dascore.spool`](`dascore.spool`) function.

For example:

```{python}
#| output: false

import dascore
from dascore import examples as ex

# Get a directory with several files
diverse_spool = dascore.get_example_spool('diverse_das')
path = ex.spool_to_directory(diverse_spool)

# Create a spool for interacting with the files in the directory.
spool = (
  dascore.spool(path)
  .select(network='das2')  # sub-select das2 network
  .select(time=(None, '2022-01-01'))  # unselect anything after 2022
  .chunk(time=2, overlap=0.5)  # change the chunking of the patches
)

# Iterate each patch and do something with it
for patch in spool:
  ...
```

## Converting Patches to Other Library Formats

The `Patch.io` namespace also includes functionality for converting `Patch` instances to datastructures used by other libraries including Pandas, Xarray, and ObsPy. See the [external conversion recipe](../recipes/external_conversion.qmd) for examples.


## Directory Indexer
The 'DirectoryIndexer' is used to track the contents of a directory which
contains fiber data. It creates a small, hidden HDF index file at the top
of the directory which can be efficiently queried for directory contents
(it is used internally by the `DirectorySpool`).


```{python}
#| output: false
import dascore
from dascore.io.indexer import DirectoryIndexer
from dascore import examples as ex

# Get a directory with several files
diverse_spool = dascore.get_example_spool('diverse_das')
path = ex.spool_to_directory(diverse_spool)

# Create an indexer and update the index. This will include any new files
# with timestamps newer than the last update, or create a new HDF index file
# if one does not yet exist.
indexer = DirectoryIndexer(path).update()

# get the contents of the directory's files
df = indexer.get_contents()

# This dataframe can be used to ascertain data availability, detect gaps, etc.
```

```{python}
#| echo: false

from IPython.display import display

display(df.head())
```
