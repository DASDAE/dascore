---
title: "Real-Time Processing"
execute:
  eval: false
---


This recipe serves as an example to showcase the real-time processing capability of DASCore. Here, we demonstrate how to use DASCore to perform rolling mean processing on a spool in real-time.


## Load libraries and get a spool

```{python}
# Import libraries
import os
import time

import dascore as dc
import numpy as np

from dascore.units import s 


# Define path for saving results
output_data_folder = '/path/to/desired/output/directory'

# Get a spool to work on
sp = dc.get_example_spool().sort("time").update()
```

## Set real-time processing parameters (if needed)

In this section, we define the window size and step size required for [rolling](https://dascore.org/api/dascore/proc/rolling/rolling.html) mean processing. With a sampling interval of 10 seconds, the cutoff frequency (Nyquist frequency) is determined to be 0.05 Hz. Additionally, we establish the desired wait time after each run by using the `sleep_time_mult` parameter, which acts as a multiplier coefficient for the number of seconds in each patch.

```{python}
# Define the target sampling interval (in sec.)
dt = 10 

# Determine window size 
window = dt*s

# Determine step size 
step = dt*s

# Set the desired wait time after each run
sleep_time_mult = 1.2
```

## Real-time processing

Eventually, we use a while loop to frequently call the spool and perform the processing. The while loop breaks if there are no new patches in the spool.

```{python}
# Start the for loop for real-time processing
i = 0
while True:
    initial_run = (i == 0)
    run_num = i+1
    print(f"\nRun number: {run_num}")

    # Select a updated sub-spool
    sp = dc.spool(data_path).sort("time").update()
    len_updated_sp = len(sp)

    # Get number of seconds in the first patch 
    sampling_interval = sp[0].attrs['d_time']
    num_sec = len(sp[0].coords["time"]) * sampling_interval 

    # Set sleep time after each run to the 
    sleep_time = num_sec * sleep_time_mult

    # Break the while loop if there are no new patches in the spool
    if not initial_run and len_last_sp == len_updated_sp: 
        print("No new data was detected in the spool after the set sleep time. "
            "Consider increasing the sleep time multiplier coefficient.")
        
        # Sleep longer
        time.sleep(4*num_sec)    

        # Check whether new data was detected in the spool
        sp = dc.spool(data_path).sort("time").update()
        len_updated_sp = len(sp)

        if len_last_sp == len_updated_sp:
            print(f"No new data was detected in spool even after "
                "four times of patch time, {4*num_sec} sec. "
                "Real-time data processing ended successfully.")
            break

    # Do processing on each patch in the spool
    for j, patch in enumerate (sp[len_last_sp:]): 
        print(f"Working on patch number: {j}")

        # Do processing
        rolling_mean_patch = patch.rolling(time=window, step=step, engine="numpy").mean()

        # Save results 
        file_name = sp.get_contents()["path"][j]
        output_path = os.path.join(output_data_folder, file_name)
        rolling_mean_patch.io.write(output_path, "dasdae")

    len_last_sp = len(sp)
    i+=1

    # Wait for new data to get into the data_path before proceeding with a new run
    time.sleep(sleep_time)
```
